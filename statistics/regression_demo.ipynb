{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows',300)\n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_colwidth',80)\n",
    "pd.set_option('display.precision',4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Underlying model: $y(n)=C+\\sum w_ix_i(n)+e(n)$, where\n",
    "- $c$ is a constant, $w_i$ are coefficients for $x_i$, they are to be estimated\n",
    "- $e(n)$ is noise components are $n$th instance\n",
    "- N is total number of samples, K is model complexity\n",
    "- minimize cost function $\\min\\sum_i (\\hat y(n) - y(n))^2$, which is a Maximum Likelihood estimator under additive Gaussian white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.5\n",
      "w=[-0.58054175  1.37679722  1.27579791]\n",
      "sigma=0.3\n"
     ]
    }
   ],
   "source": [
    "# simulated data model\n",
    "complexity, C, N = 3, 0.5, 15\n",
    "\n",
    "w=np.random.randn(complexity)*2\n",
    "x=np.random.randn(N, complexity)\n",
    "y=x.dot(w)\n",
    "sigma = 0.3\n",
    "e=sigma*np.random.randn(*y.shape)\n",
    "y=y+e+C\n",
    "print(f\"C={C}\")\n",
    "print(f\"w={w}\")\n",
    "print(f\"sigma={sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear regression or least squares estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.linalg.lstsq\n",
      "[ 0.59756759 -0.42428839  1.3495217   1.26195729] \n",
      "\n",
      "scipy.optimize.lsq_linear\n",
      "[ 0.59756759 -0.42428839  1.3495217   1.26195729] \n",
      "\n",
      "scikit-learn LinearRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5975675885841535"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.42428839,  1.3495217 ,  1.26195729])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9774602640345035"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels OLS solver\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.59756759, -0.42428839,  1.3495217 ,  1.26195729])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1394: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   159.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 10 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.44e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:19:08</td>     <th>  Log-Likelihood:    </th> <td> 0.75902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    15</td>      <th>  AIC:               </th> <td>   6.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    11</td>      <th>  BIC:               </th> <td>   9.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5976</td> <td>    0.075</td> <td>    7.945</td> <td> 0.000</td> <td>    0.432</td> <td>    0.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.4243</td> <td>    0.076</td> <td>   -5.618</td> <td> 0.000</td> <td>   -0.591</td> <td>   -0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.3495</td> <td>    0.073</td> <td>   18.558</td> <td> 0.000</td> <td>    1.189</td> <td>    1.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.2620</td> <td>    0.076</td> <td>   16.582</td> <td> 0.000</td> <td>    1.094</td> <td>    1.429</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy least squares\n",
    "from numpy import linalg\n",
    "print(\"numpy.linalg.lstsq\")\n",
    "# X_stack = np.hstack([np.ones((x.shape[0], 1)), x])\n",
    "X_stack = np.concatenate([np.ones((x.shape[0], 1)), x], axis=1)\n",
    "model = linalg.lstsq(X_stack, y, rcond=None)\n",
    "print(model[0], \"\\n\")\n",
    "\n",
    "# scipy optimize\n",
    "from scipy.optimize import lsq_linear\n",
    "print(\"scipy.optimize.lsq_linear\")\n",
    "model = lsq_linear(X_stack, y)\n",
    "print(model.x, \"\\n\")\n",
    "\n",
    "# scikit learn linear regressor\n",
    "print(\"scikit-learn LinearRegressor\")\n",
    "model = LinearRegression().fit(x, y)\n",
    "model.intercept_\n",
    "model.coef_\n",
    "model.score(x, y)\n",
    "\n",
    "# statsmodels OLS solver\n",
    "print(\"statsmodels OLS solver\")\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.params\n",
    "summary=model.summary()\n",
    "HTML(summary.tables[0].as_html())\n",
    "HTML(summary.tables[1].as_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand OLS summary\n",
    "### Goodness of fit $R^2$: \n",
    "The variance of dependent variable $y(n)$ (sum of squares total **SST**), can be partition into two terms: sum of squares regression **SSR** and sum of squares error **SSE**. Denote y estimates $\\hat y(n)=w^tX(n)$, y mean $\\bar y=\\frac{1}{N}\\sum_n^N y(n)$ <br>\n",
    "$$\\begin{align}\n",
    "SST=&\\sum_i^N (y-\\bar y)^2 & \\\\\n",
    "SSR=&\\sum_i^N(w^TX-\\bar y)^2 & \\\\\n",
    "SSE=&\\sum_{i}^{N}(y-\\hat y)^2 & \\\\\n",
    "\\end{align}$$<br>\n",
    "The coefficient of determination $R^2$, is defined as ration of SSR over SST. $R^2$ ranges [0, 1], 1 being a perfect fit. <br>\n",
    "$$\\begin{align}\n",
    "R^2=\\frac{SSR}{SST}=1-\\frac{SSE}{SST}\n",
    "\\end{align}$$\n",
    "\n",
    "### F-test\n",
    "F-test evaluates the significance of the entire regression, where the null hypothesis is that all the regressors (coefficients) except yhe constant are 0, i.e., $w_i=0,\\ \\forall i$. <br>\n",
    "F-statistics under the null hypothesis follows F-distribution with (K-1, N-k) degree of freedom\n",
    "$$F=\\frac{SSR/(K-1)}{SSE/(N-K)}\\approx F(\\frac{SSR}{SSE})_{K-1,N-K}$$\n",
    "Rewrite F-statistic in terms of $R^2$, notice for fixed $R^2$, F-statistics decreases with increasing number of predictor $K$.\n",
    "$$F=\\frac{(N-K)R^2}{(K-1)(1-R^2)}$$\n",
    "\n",
    "### Invidual test statistics (t-test)\n",
    "Determine whether a weight/regressor is statistically significant. Each coefficient estimate, follows t-distribution.  \n",
    "The t-statistics for kth regression coefficient under $H_0$ that $x_k$ and $y$ are independent follow t-distribution with n-K degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
